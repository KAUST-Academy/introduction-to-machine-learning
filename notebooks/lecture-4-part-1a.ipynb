{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqXqSwkNMZnh"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, model_selection, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZWFwAtSMf2-"
      },
      "source": [
        "# Linear Regression from Scratch with Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data"
      ],
      "metadata": {
        "id": "SpXhpfzQSJwW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sI9mlHKMi0G"
      },
      "outputs": [],
      "source": [
        "datasets.make_regression?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si6PQ9vhMxP8"
      },
      "outputs": [],
      "source": [
        "prng = np.random.RandomState(42)\n",
        "X, y, theta = datasets.make_regression(\n",
        "    n_features=1,\n",
        "    n_informative=1,\n",
        "    noise=10.0,\n",
        "    coef=True,\n",
        "    random_state=prng\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFl-qannNNQx"
      },
      "outputs": [],
      "source": [
        "_ = plt.plot(X[:, 0], y, 'o')\n",
        "_ = plt.xlabel(r\"$X_1$\", fontsize=15)\n",
        "_ = plt.ylabel(\"y\", fontsize=15, rotation=0)\n",
        "_ = plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "id": "TcTb7MoLQVSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "M9pMA9X7BkUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_features, shuffled_targets = utils.shuffle(X, y, random_state=prng)\n",
        "train_features, train_targets = shuffled_features[:80], shuffled_targets[:80]\n",
        "test_features, test_targets = shuffled_features[80:], shuffled_targets[80:]"
      ],
      "metadata": {
        "id": "yVjNksoVikMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "d1tGIPzaBm-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, theta):\n",
        "    return X @ theta\n",
        "\n",
        "\n",
        "def mse_loss(y, y_hat):\n",
        "    return 0.5 * np.mean((y - y_hat)**2)\n",
        "\n",
        "\n",
        "def mse_grad(X, y, y_hat):\n",
        "    m, *_ = y.shape\n",
        "    return -(1 / m) * (X.T @ (y - y_hat))\n",
        "\n"
      ],
      "metadata": {
        "id": "CaTdxwpoBpay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analytic Solution"
      ],
      "metadata": {
        "id": "ZCK0ti1NX33E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(X, y):\n",
        "    return np.linalg.inv(X.T @ X) @ X.T @ y"
      ],
      "metadata": {
        "id": "mHQ8N2d2X6Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta_hat = linear_regression(train_features, train_targets)"
      ],
      "metadata": {
        "id": "5bw4lJrLHOc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta_hat"
      ],
      "metadata": {
        "id": "Tt_7DXmOHOmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = predict(train_features, theta_hat)\n",
        "mse_loss(train_targets, train_predictions)"
      ],
      "metadata": {
        "id": "8sW14V1wDAJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = predict(test_features, theta_hat)\n",
        "mse_loss(test_targets, test_predictions)"
      ],
      "metadata": {
        "id": "d4sXyWN9HOqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ordlmc5YXB2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "H-cn_qp-DMz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZeA-5v8P82e"
      },
      "outputs": [],
      "source": [
        "def model_fn(X, learned_parameters):\n",
        "    return predict(X, learned_parameters)\n",
        "\n",
        "\n",
        "def loss_fn(y, y_hat):\n",
        "    return mse_loss(y, y_hat)\n",
        "\n",
        "\n",
        "def grad_fn(X, y, y_hat):\n",
        "    return mse_grad(X, y, y_hat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1izaWjUP_rJ"
      },
      "outputs": [],
      "source": [
        "# initialize weights\n",
        "learned_parameters = prng.normal(loc=0, scale=1, size=(1,))\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 1\n",
        "epochs = 100\n",
        "log_epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for batch_ixs in utils.gen_batches(len(train_targets), batch_size):\n",
        "        features, target = train_features[batch_ixs], train_targets[batch_ixs]\n",
        "\n",
        "        # forward pass\n",
        "        predictions = model_fn(features, learned_parameters)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        total_loss += loss\n",
        "\n",
        "        # backward pass\n",
        "        grad = grad_fn(features, target, predictions)\n",
        "        learned_parameters -= grad * learning_rate\n",
        "\n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f\"Epoch {epoch}  Loss {total_loss / len(train_targets):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcFDpL30y99V"
      },
      "outputs": [],
      "source": [
        "print(f\"Learned Parameters:\\n {learned_parameters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQbRLvFCnTr"
      },
      "outputs": [],
      "source": [
        "total_loss = 0\n",
        "for batch_ixs in utils.gen_batches(len(test_targets), batch_size):\n",
        "    features, target = test_features[batch_ixs], test_targets[batch_ixs]\n",
        "    predictions = model_fn(features, learned_parameters)\n",
        "    loss = loss_fn(target, predictions)\n",
        "    total_loss += loss\n",
        "\n",
        "print(f\"Average test loss: {total_loss / len(test_targets)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUxsbvw4TNg1"
      },
      "outputs": [],
      "source": [
        "_ = plt.plot(X[:, 0], y, 'o')\n",
        "_ = plt.xlabel(r\"$X_1$\", fontsize=15)\n",
        "_ = plt.ylabel(\"y\", fontsize=15, rotation=0)\n",
        "\n",
        "X_new = np.linspace(-3, 3, 1000).reshape((-1, 1))\n",
        "y_new = model_fn(X_new, learned_parameters)\n",
        "\n",
        "_ = plt.plot(X_new[:, 0], y_new)\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agHnE83Gie-t"
      },
      "source": [
        "## Example using a real data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic_KeQvHUR8"
      },
      "outputs": [],
      "source": [
        "features, targets = datasets.load_diabetes(\n",
        "    return_X_y=True,\n",
        "    as_frame=False,\n",
        "    scaled=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRKDrTgqHUR8"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "id": "x4-uuq_fClPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "iRuGO5YhhC86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, test_features, train_targets, test_targets = (\n",
        "    model_selection.train_test_split(\n",
        "        features,\n",
        "        targets,\n",
        "        random_state=prng,\n",
        "        test_size=0.1\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "3bPVLcg5IaLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analytic Solution"
      ],
      "metadata": {
        "id": "910DJ9vGhk8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9sAUxuqHUR-"
      },
      "outputs": [],
      "source": [
        "learned_parameters = linear_regression(train_features, train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = predict(train_features, learned_parameters)\n",
        "training_loss = loss_fn(train_targets, train_predictions)\n",
        "print(f\"Training loss: {np.sqrt(training_loss)}\")"
      ],
      "metadata": {
        "id": "kga4xYZpjI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = predict(test_features, learned_parameters)\n",
        "test_loss = loss_fn(test_targets, test_predictions)\n",
        "print(f\"Test loss: {np.sqrt(test_loss)}\")"
      ],
      "metadata": {
        "id": "fAqkSNQDjJCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "h3JwOS2MhyJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329CnQnEHUR-"
      },
      "outputs": [],
      "source": [
        "# initialize weights\n",
        "_, n = train_features.shape\n",
        "learned_parameters = prng.normal(loc=0, scale=1, size=(n,))\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 32\n",
        "epochs = 1000\n",
        "log_epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for batch_ixs in utils.gen_batches(len(train_targets), batch_size):\n",
        "        features = train_features[batch_ixs]\n",
        "        target = train_targets[batch_ixs]\n",
        "\n",
        "        # forward pass\n",
        "        predictions = model_fn(features, learned_parameters)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        total_loss += loss\n",
        "\n",
        "        # backward pass\n",
        "        grad = grad_fn(features, target, predictions)\n",
        "        learned_parameters -= grad * learning_rate\n",
        "\n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {total_loss / len(train_targets):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = model_fn(train_features, learned_parameters)\n",
        "training_loss = loss_fn(train_targets, train_predictions)\n",
        "print(f\"Training loss: {np.sqrt(training_loss)}\")"
      ],
      "metadata": {
        "id": "xhHdqI8TB3Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNHrKRGYHUR_"
      },
      "outputs": [],
      "source": [
        "test_predictions = model_fn(test_features, learned_parameters)\n",
        "test_loss = loss_fn(test_targets, test_predictions)\n",
        "print(f\"Test loss: {np.sqrt(test_loss)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Compare the training loss and the testing loss. Is the model underfitting or overfitting? How can you tell?"
      ],
      "metadata": {
        "id": "R-dC8-3hauIk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqj37ufbG2nP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}