{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyktIROxgkUJ"
      },
      "source": [
        "# Prepare the Data for Machine Learning Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Data"
      ],
      "metadata": {
        "id": "MQgd1GD_jyFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "def download_data(url, data_dir):\n",
        "    with open(data_dir / \"housing.tgz\", 'wb') as f:\n",
        "        response = requests.get(url)\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def extract_data(data_dir):\n",
        "    with tarfile.open(data_dir / \"housing.tgz\") as tgz:\n",
        "        tgz.extractall(path=data_dir)\n",
        "\n",
        "\n",
        "# load the data\n",
        "url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
        "data_dir = pathlib.Path(\"./sample_data\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "download_data(url, data_dir)\n",
        "extract_data(data_dir)\n",
        "housing_df = pd.read_csv(data_dir / \"housing\" / \"housing.csv\")\n",
        "\n",
        "# stratified sampling to match the income distribution\n",
        "housing_df[\"income_cat\"] = pd.cut(\n",
        "    housing_df[\"median_income\"],\n",
        "    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "    labels=[0, 1, 2, 3, 4]\n",
        ")\n",
        "\n",
        "train_df, test_df = model_selection.train_test_split(\n",
        "    housing_df,\n",
        "    test_size=0.2,\n",
        "    stratify=housing_df.loc[:, \"income_cat\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_df.drop(\"income_cat\", axis=1, inplace=True)\n",
        "test_df.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "RnK2OrzEjxtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS-jktdNgkUJ"
      },
      "outputs": [],
      "source": [
        "# split off the features and the target\n",
        "train_features_df = train_df.drop(\"median_house_value\", axis=1)\n",
        "train_targets = train_df.loc[:, \"median_house_value\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_df.info()"
      ],
      "metadata": {
        "id": "Gliz8hhgkVRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDg2D8YGgkUJ"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOEMXbOggkUK"
      },
      "outputs": [],
      "source": [
        "from sklearn import impute\n",
        "\n",
        "\n",
        "imputer = (\n",
        "    impute.SimpleImputer(strategy=\"median\")\n",
        "          .set_output(transform=\"pandas\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imputer"
      ],
      "metadata": {
        "id": "V2t19qAxksFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8bkWytdgkUK"
      },
      "source": [
        "Separating out the numerical attributes to use the `\"median\"` strategy (as it cannot be calculated on text attributes like `ocean_proximity`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUT5--yQgkUK"
      },
      "outputs": [],
      "source": [
        "numeric_features_df = train_features_df.select_dtypes(include=[np.number])\n",
        "_ = imputer.fit(numeric_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y16yormgkUK"
      },
      "outputs": [],
      "source": [
        "imputer.statistics_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHAaa7X2gkUK"
      },
      "source": [
        "Check that this is the same as manually computing the median of each attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dkY4NNXgkUK"
      },
      "outputs": [],
      "source": [
        "numeric_features_df.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoDp51ngkUL"
      },
      "source": [
        "Transform the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOE5DdqggkUL"
      },
      "outputs": [],
      "source": [
        "imputed_numeric_features_df = imputer.transform(numeric_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6XOUeeDgkUL"
      },
      "outputs": [],
      "source": [
        "imputer.feature_names_in_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3XUcPLIgkUL"
      },
      "outputs": [],
      "source": [
        "imputed_numeric_features_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqpnjwrQgkUL"
      },
      "source": [
        "Now let's drop some outliers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twHf9Vh4gkUM"
      },
      "outputs": [],
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "\n",
        "isolation_forest = ensemble.IsolationForest(random_state=42)\n",
        "isolation_forest.fit_predict(imputed_numeric_features_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp0idhZngkUM"
      },
      "source": [
        "If you wanted to drop outliers, you would run the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yH6gud8RgkUM"
      },
      "outputs": [],
      "source": [
        "#housing = housing.iloc[outlier_pred == 1]\n",
        "#housing_labels = housing_labels.iloc[outlier_pred == 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIZoJBrPgkUM"
      },
      "source": [
        "## Handling Text and Categorical Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hFQgLK-gkUM"
      },
      "source": [
        "Now let's preprocess the categorical input feature, `ocean_proximity`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5olOzVBpgkUM"
      },
      "outputs": [],
      "source": [
        "train_df.loc[:, [\"ocean_proximity\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMnrJLhEgkUM"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "ordinal_encoder = (\n",
        "    preprocessing.OrdinalEncoder()\n",
        "                 .set_output(transform=\"pandas\")\n",
        ")\n",
        "ordinal_encoded_ocean_proximity = (\n",
        "    ordinal_encoder.fit_transform(train_df.loc[:, [\"ocean_proximity\"]])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxw7bv22gkUM"
      },
      "outputs": [],
      "source": [
        "ordinal_encoded_ocean_proximity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OF9njWFgkUM"
      },
      "outputs": [],
      "source": [
        "ordinal_encoder.categories_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKWcmapogkUN"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder = (\n",
        "    preprocessing.OneHotEncoder(sparse_output=False)\n",
        "                 .set_output(transform=\"pandas\")\n",
        ")\n",
        "one_hot_encoded_ocean_proximity = (\n",
        "    one_hot_encoder.fit_transform(train_df.loc[:, [\"ocean_proximity\"]])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3QA8lSzgkUN"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded_ocean_proximity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1M_aAQOgkUN"
      },
      "outputs": [],
      "source": [
        "one_hot_encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sG3gcpugkUO"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHfQOy-8gkUO"
      },
      "outputs": [],
      "source": [
        "min_max_scaler = (\n",
        "    preprocessing.MinMaxScaler(\n",
        "      feature_range=(-1, 1)\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "min_max_scaled_numeric_features_df = (\n",
        "    min_max_scaler.fit_transform(numeric_features_df)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scaled_numeric_features_df.describe()"
      ],
      "metadata": {
        "id": "5Zji3bzfpO3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHkZZSbtgkUO"
      },
      "outputs": [],
      "source": [
        "standard_scaler = (\n",
        "    preprocessing.StandardScaler()\n",
        "                 .set_output(transform=\"pandas\")\n",
        ")\n",
        "standard_scaled_numeric_features_df = (\n",
        "    standard_scaler.fit_transform(numeric_features_df)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standard_scaled_numeric_features_df.describe()"
      ],
      "metadata": {
        "id": "EDKRGRfJpSQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zv4TT9bgkUP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
        "train_df.loc[:, \"population\"].hist(ax=axs[0], bins=50)\n",
        "train_df.loc[:, \"population\"].apply(np.log).hist(ax=axs[1], bins=50)\n",
        "axs[0].set_xlabel(\"Population\")\n",
        "axs[1].set_xlabel(\"Log of population\")\n",
        "axs[0].set_ylabel(\"Number of districts\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_transformer = (\n",
        "    preprocessing.FunctionTransformer(\n",
        "        func=np.log,\n",
        "        inverse_func=np.exp\n",
        "    )\n",
        ")\n",
        "log_population = log_transformer.fit_transform(train_df.loc[:, [\"population\"]])"
      ],
      "metadata": {
        "id": "IadfL-qXrAzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_population"
      ],
      "metadata": {
        "id": "2OZ_Z0l6rTpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmYCzZIogkUP"
      },
      "source": [
        "What if we replace each value of `median_income` with its quantile?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = (\n",
        "    train_df.loc[:, \"median_income\"]\n",
        "            .hist(bins=50)\n",
        ")"
      ],
      "metadata": {
        "id": "9ycLSTKTszb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantile_transformer = (\n",
        "    preprocessing.QuantileTransformer(\n",
        "        n_quantiles=100,\n",
        "        output_distribution=\"uniform\"\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "quantiled_median_income = (\n",
        "    quantile_transformer.fit_transform(train_df.loc[:, [\"median_income\"]])\n",
        ")"
      ],
      "metadata": {
        "id": "rj5vAcp0sG52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = quantiled_median_income.hist(bins=50)"
      ],
      "metadata": {
        "id": "RZU6C2DgtHcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4avIpXxCgkUP"
      },
      "source": [
        "## Custom Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6YbSOwcgkUQ"
      },
      "outputs": [],
      "source": [
        "from sklearn import base, cluster, metrics\n",
        "\n",
        "\n",
        "class ClusterSimilarity(base.BaseEstimator, base.TransformerMixin):\n",
        "\n",
        "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.gamma = gamma\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        kmeans = cluster.KMeans(\n",
        "            self.n_clusters,\n",
        "            n_init=10,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "        self.kmeans_ = kmeans.fit(X, sample_weight=sample_weight)\n",
        "        return self  # always return self!\n",
        "\n",
        "    def transform(self, X):\n",
        "        similarities = (\n",
        "            metrics.pairwise\n",
        "                   .rbf_kernel(\n",
        "                       X,\n",
        "                       Y=self.kmeans_.cluster_centers_,\n",
        "                       gamma=self.gamma\n",
        "                   )\n",
        "        )\n",
        "        return similarities\n",
        "\n",
        "    def get_feature_names_out(self, names=None):\n",
        "        return [f\"cluster_{i:02d}_similarity\" for i in range(self.n_clusters)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QdgXtA-gkUQ"
      },
      "outputs": [],
      "source": [
        "cluster_similarity = (\n",
        "    ClusterSimilarity(\n",
        "        n_clusters=10,\n",
        "        gamma=1.,\n",
        "        random_state=42\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "similarities = (\n",
        "    cluster_similarity .fit_transform(\n",
        "        train_df.loc[:, [\"latitude\", \"longitude\"]],\n",
        "        sample_weight=train_targets\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfThri__gkUQ"
      },
      "outputs": [],
      "source": [
        "similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfpx_mSWgkUQ"
      },
      "source": [
        "## Transformation Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhIsNsNngkUQ"
      },
      "source": [
        "Now let's build a pipeline to preprocess the numerical attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aa40nyWgkUQ"
      },
      "outputs": [],
      "source": [
        "from sklearn import pipeline\n",
        "\n",
        "\n",
        "numeric_pipeline = (\n",
        "    pipeline.Pipeline(\n",
        "        [\n",
        "            (\"simple_impute\", impute.SimpleImputer(strategy=\"median\")),\n",
        "            (\"standard_scaler\", preprocessing.StandardScaler()),\n",
        "        ],\n",
        "        verbose=True\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKPXkUEygkUR"
      },
      "outputs": [],
      "source": [
        "numeric_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"median\"),\n",
        "        preprocessing.StandardScaler(),\n",
        "        verbose=True\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_pipeline"
      ],
      "metadata": {
        "id": "Tq20xaD7zVdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhiCQgPOgkUR"
      },
      "outputs": [],
      "source": [
        "prepared_numeric_features_df = numeric_pipeline.fit_transform(numeric_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_numeric_features_df"
      ],
      "metadata": {
        "id": "gCg83r6IzMyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AZM_aavgkUR"
      },
      "outputs": [],
      "source": [
        "numeric_pipeline.steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Daq84duogkUR"
      },
      "outputs": [],
      "source": [
        "numeric_pipeline[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9thz977gkUR"
      },
      "outputs": [],
      "source": [
        "numeric_pipeline[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df4e6axqgkUR"
      },
      "outputs": [],
      "source": [
        "numeric_pipeline.named_steps[\"simpleimputer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlL7mCQlgkUR"
      },
      "outputs": [],
      "source": [
        "numeric_pipeline.set_params(simpleimputer__strategy=\"median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1qAl-SJgkUR"
      },
      "outputs": [],
      "source": [
        "from sklearn import compose\n",
        "\n",
        "\n",
        "numeric_features = [\n",
        "    \"longitude\",\n",
        "    \"latitude\",\n",
        "    \"housing_median_age\",\n",
        "    \"total_rooms\",\n",
        "    \"total_bedrooms\",\n",
        "    \"population\",\n",
        "    \"households\",\n",
        "    \"median_income\"\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    \"ocean_proximity\"\n",
        "]\n",
        "\n",
        "categorical_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"most_frequent\"),\n",
        "        preprocessing.OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "preprocessing_pipeline = (\n",
        "    compose.ColumnTransformer(\n",
        "        [\n",
        "            (\"numeric_pipeline\", numeric_pipeline, numeric_features),\n",
        "            (\"categorical_pipeline\", categorical_pipeline, categorical_features),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "        n_jobs=-1,\n",
        "        verbose=True,\n",
        "        verbose_feature_names_out=False\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AEV0aYOgkUR"
      },
      "outputs": [],
      "source": [
        "preprocessing_pipeline = (\n",
        "    compose.make_column_transformer(\n",
        "        (numeric_pipeline, compose.make_column_selector(dtype_include=np.number)),\n",
        "        (categorical_pipeline, compose.make_column_selector(dtype_include=object)),\n",
        "        remainder=\"drop\",\n",
        "        n_jobs=-1,\n",
        "        verbose=True,\n",
        "        verbose_feature_names_out=False\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline"
      ],
      "metadata": {
        "id": "0bW2l9xV0a1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL1m5b9EgkUS"
      },
      "outputs": [],
      "source": [
        "prepared_features_df = preprocessing_pipeline.fit_transform(train_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RosrFo18gkUS"
      },
      "outputs": [],
      "source": [
        "prepared_features_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lClmToGtgkUS"
      },
      "outputs": [],
      "source": [
        "def column_ratio(df):\n",
        "    return df.iloc[:, 0] / df.iloc[:, 1]\n",
        "\n",
        "\n",
        "def ratio_name(function_transformer, feature_names_in):\n",
        "    return [\"ratio\"]  # feature names out\n",
        "\n",
        "\n",
        "def make_ratio_pipeline():\n",
        "    ratio_pipeline = (\n",
        "        pipeline.make_pipeline(\n",
        "            impute.SimpleImputer(strategy=\"median\"),\n",
        "            preprocessing.FunctionTransformer(column_ratio, feature_names_out=ratio_name),\n",
        "            preprocessing.StandardScaler(),\n",
        "            verbose=True\n",
        "        ).set_output(\n",
        "            transform=\"pandas\"\n",
        "        )\n",
        "    )\n",
        "    return ratio_pipeline\n",
        "\n",
        "\n",
        "log_transform_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"median\"),\n",
        "        preprocessing.FunctionTransformer(np.log, np.exp, feature_names_out=\"one-to-one\"),\n",
        "        preprocessing.StandardScaler()\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "cluster_similarity = (\n",
        "    ClusterSimilarity(\n",
        "        n_clusters=10,\n",
        "        gamma=1.,\n",
        "        random_state=42\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "default_numeric_pipeline = (\n",
        "    pipeline.make_pipeline(\n",
        "        impute.SimpleImputer(strategy=\"median\"),\n",
        "        preprocessing.StandardScaler(),\n",
        "        verbose=True\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")\n",
        "\n",
        "preprocessing_pipeline = (\n",
        "    compose.ColumnTransformer(\n",
        "        [\n",
        "            (\"bedrooms\", make_ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]),\n",
        "            (\"rooms_per_house\", make_ratio_pipeline(), [\"total_rooms\", \"households\"]),\n",
        "            (\"people_per_house\", make_ratio_pipeline(), [\"population\", \"households\"]),\n",
        "            (\"log\", log_transform_pipeline, [\"total_bedrooms\", \"total_rooms\", \"population\", \"households\", \"median_income\"]),\n",
        "            (\"geo\", cluster_similarity, [\"latitude\", \"longitude\"]),\n",
        "            (\"categorical\", categorical_pipeline, compose.make_column_selector(dtype_include=object)),\n",
        "        ],\n",
        "        n_jobs=-1,\n",
        "        remainder=default_numeric_pipeline,\n",
        "        verbose=True\n",
        "    ).set_output(\n",
        "        transform=\"pandas\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline"
      ],
      "metadata": {
        "id": "qirrGxvo33Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yx7kVk3gkUS"
      },
      "outputs": [],
      "source": [
        "prepared_features_df = preprocessing_pipeline.fit_transform(train_features_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_features_df"
      ],
      "metadata": {
        "id": "ipDNDpKx3_9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LFEeZQd79Raq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}