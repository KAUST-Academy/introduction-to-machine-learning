{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqXqSwkNMZnh"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, model_selection, pipeline, preprocessing, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZWFwAtSMf2-"
      },
      "source": [
        "# Linear Regression from Scratch with Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sI9mlHKMi0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ7gP_USMul2"
      },
      "source": [
        "## Small example with synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si6PQ9vhMxP8"
      },
      "outputs": [],
      "source": [
        "prng = np.random.RandomState(42)\n",
        "m = 100\n",
        "features = [\n",
        "    np.ones((m, 1)),\n",
        "    prng.normal(loc=1.0, scale=1.0, size=(m, 1))\n",
        "]\n",
        "X = np.hstack(features)\n",
        "error = prng.normal(loc=0.0, scale=5e-1, size=(m, 1))\n",
        "beta = np.array([[3.0], [1.5]])\n",
        "y = X @ beta + error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFl-qannNNQx"
      },
      "outputs": [],
      "source": [
        "_ = plt.plot(X[:, 1], y, 'o')\n",
        "_ = plt.xlabel(r\"$X_1$\", fontsize=15)\n",
        "_ = plt.ylabel(\"y\", fontsize=15, rotation=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "M9pMA9X7BkUM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arb3VEomvR3u"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_target, test_target = model_selection.train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=prng\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "d1tGIPzaBm-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_regression(X, y):\n",
        "    return np.linalg.inv(X.T @ X) @ X.T @ y"
      ],
      "metadata": {
        "id": "CaTdxwpoBpay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta_hat = linear_regression(train_features, train_target)"
      ],
      "metadata": {
        "id": "5bw4lJrLHOc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta_hat"
      ],
      "metadata": {
        "id": "Tt_7DXmOHOmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y, y_hat):\n",
        "    return 0.5 * np.mean((y - y_hat)**2)"
      ],
      "metadata": {
        "id": "NSm6EPBIClqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = train_features @ beta_hat\n",
        "loss_fn(train_target, train_predictions)"
      ],
      "metadata": {
        "id": "8sW14V1wDAJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on the test set"
      ],
      "metadata": {
        "id": "U7dryqm6CTNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_features @ beta_hat\n",
        "loss_fn(test_target, test_predictions)"
      ],
      "metadata": {
        "id": "d4sXyWN9HOqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Stochastic Gradient Descent "
      ],
      "metadata": {
        "id": "H-cn_qp-DMz4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZeA-5v8P82e"
      },
      "outputs": [],
      "source": [
        "# initialize weights\n",
        "learned_parameters = prng.normal(loc=0, scale=1, size=(2, 1))\n",
        "\n",
        "\n",
        "def model_fn(X):\n",
        "    return X @ learned_parameters\n",
        "\n",
        "def grad_fn(X, y, y_hat):\n",
        "    m, _ = y.shape\n",
        "    return -(1 / m) * (X.T @ (y - y_hat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1izaWjUP_rJ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 1\n",
        "epochs = 100\n",
        "log_epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for batch_ixs in utils.gen_batches(len(train_target), batch_size):\n",
        "        features, target = train_features[batch_ixs], train_target[batch_ixs]\n",
        "\n",
        "        # forward pass\n",
        "        predictions = model_fn(features)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        total_loss += loss\n",
        "        \n",
        "        # backward pass\n",
        "        grad = grad_fn(features, target, predictions)\n",
        "        learned_parameters -= grad * learning_rate\n",
        "  \n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {total_loss / len(train_target):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcFDpL30y99V"
      },
      "outputs": [],
      "source": [
        "print(f'Final Parameters: {learned_parameters[:, 0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQbRLvFCnTr"
      },
      "outputs": [],
      "source": [
        "total_loss = 0\n",
        "for batch_ixs in utils.gen_batches(len(test_target), batch_size):\n",
        "    features, target = test_features[batch_ixs], test_target[batch_ixs]\n",
        "    predictions = model_fn(features)\n",
        "    loss = loss_fn(target, predictions)\n",
        "    total_loss += loss\n",
        "\n",
        "print(f\"Average test loss: {total_loss / len(test_target)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUxsbvw4TNg1"
      },
      "outputs": [],
      "source": [
        "_ = plt.plot(X[:, 1], y, 'o')\n",
        "_ = plt.xlabel(r\"$X_1$\", fontsize=15)\n",
        "_ = plt.ylabel(\"y\", fontsize=15, rotation=0)\n",
        "\n",
        "new_features = [\n",
        "    np.ones((m, 1)),\n",
        "    np.linspace(-2, 4, m).reshape((-1, 1))    \n",
        "]\n",
        "X_new = np.hstack(new_features)\n",
        "y_new = model_fn(X_new)\n",
        "\n",
        "_ = plt.plot(X_new[:, 1], y_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agHnE83Gie-t"
      },
      "source": [
        "## Predicting house prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic_KeQvHUR8"
      },
      "outputs": [],
      "source": [
        "datasets.fetch_california_housing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTfsl2JHUR8"
      },
      "outputs": [],
      "source": [
        "features, targets = datasets.fetch_california_housing(return_X_y=True, as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRKDrTgqHUR8"
      },
      "outputs": [],
      "source": [
        "features.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzfG-j5DHUR9"
      },
      "outputs": [],
      "source": [
        "features.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets.describe() # units are 100k USD"
      ],
      "metadata": {
        "id": "x4-uuq_fClPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "iRuGO5YhhC86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmB1B6ykHUR9"
      },
      "outputs": [],
      "source": [
        "random_state = np.random.RandomState(42)\n",
        "train_features, test_features, train_targets, test_targets = model_selection.train_test_split(\n",
        "    features,\n",
        "    targets,\n",
        "    test_size=0.1,\n",
        "    random_state=random_state,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUeWX4jBHUR9"
      },
      "outputs": [],
      "source": [
        "features_preprocessing_pipeline = pipeline.make_pipeline(\n",
        "    preprocessing.StandardScaler(),\n",
        ")\n",
        "\n",
        "targets_preprocessing_pipeline = pipeline.make_pipeline(\n",
        "    preprocessing.FunctionTransformer(lambda X: X.to_numpy()),\n",
        "    preprocessing.FunctionTransformer(lambda X: X.reshape(-1, 1)),    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N60DLvaFHUR-"
      },
      "outputs": [],
      "source": [
        "train_features_array = features_preprocessing_pipeline.fit_transform(train_features)\n",
        "train_targets_array = targets_preprocessing_pipeline.fit_transform(train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m2lVjJcHUR_"
      },
      "outputs": [],
      "source": [
        "test_features_array = features_preprocessing_pipeline.transform(test_features)\n",
        "test_targets_array = targets_preprocessing_pipeline.transform(test_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analytic Solution"
      ],
      "metadata": {
        "id": "910DJ9vGhk8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9sAUxuqHUR-"
      },
      "outputs": [],
      "source": [
        "learned_parameters = linear_regression(train_features_array, train_targets_array)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_array = model_fn(train_features_array)\n",
        "training_loss = loss_fn(predictions_array, train_targets_array)\n",
        "print(f\"Training loss: {np.sqrt(training_loss) * 100_000} USD\")"
      ],
      "metadata": {
        "id": "kga4xYZpjI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_array = model_fn(test_features_array)\n",
        "test_loss = loss_fn(predictions_array, test_targets_array)\n",
        "print(f\"Test loss: {np.sqrt(test_loss) * 100_000} USD\")"
      ],
      "metadata": {
        "id": "fAqkSNQDjJCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "h3JwOS2MhyJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize weights\n",
        "_, n = train_features_array.shape\n",
        "learned_parameters = prng.normal(loc=0, scale=1, size=(n, 1))"
      ],
      "metadata": {
        "id": "B68JGMALhxUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329CnQnEHUR-"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "log_epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    total_loss = 0.0\n",
        "    for batch_ixs in utils.gen_batches(len(train_target), batch_size):\n",
        "        features, target = train_features_array[batch_ixs], train_targets_array[batch_ixs]\n",
        "\n",
        "        # forward pass\n",
        "        predictions = model_fn(features)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        total_loss += loss\n",
        "        \n",
        "        # backward pass\n",
        "        grad = grad_fn(features, target, predictions)\n",
        "        learned_parameters -= grad * learning_rate\n",
        "  \n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {total_loss / len(train_targets_array):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_array = model_fn(train_features_array)\n",
        "\n",
        "training_loss = loss_fn(predictions_array, train_targets_array)\n",
        "print(f\"Training loss: {np.sqrt(training_loss) * 100_000} USD\")"
      ],
      "metadata": {
        "id": "xhHdqI8TB3Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNHrKRGYHUR_"
      },
      "outputs": [],
      "source": [
        "predictions_array = model_fn(test_features_array)\n",
        "test_loss = loss_fn(predictions_array, test_targets_array)\n",
        "print(f\"Test loss: {np.sqrt(test_loss) * 100_000} USD\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqj37ufbG2nP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}