{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqXqSwkNMZnh"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import compose, datasets, linear_model, metrics, model_selection\n",
        "from sklearn import preprocessing, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZWFwAtSMf2-"
      },
      "source": [
        "# Regularized Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic_KeQvHUR8"
      },
      "outputs": [],
      "source": [
        "features, targets = datasets.load_diabetes(\n",
        "    return_X_y=True,\n",
        "    as_frame=True,\n",
        "    scaled=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "iRuGO5YhhC86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prng = np.random.RandomState(42)\n",
        "\n",
        "train_features, test_features, train_targets, test_targets = (\n",
        "    model_selection.train_test_split(\n",
        "        features,\n",
        "        targets,\n",
        "        random_state=prng,\n",
        "        test_size=0.1\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "fhnKAB8P8kKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Preprocessing"
      ],
      "metadata": {
        "id": "910DJ9vGhk8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9sAUxuqHUR-"
      },
      "outputs": [],
      "source": [
        "transformer_1 = compose.make_column_transformer(\n",
        "    (\n",
        "        preprocessing.OneHotEncoder(\n",
        "            drop=\"first\",\n",
        "            dtype=np.uint8,\n",
        "            sparse_output=False,\n",
        "        ),\n",
        "        [\"sex\"]\n",
        "    ),\n",
        "    remainder=\"drop\",\n",
        "    verbose=True,\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "\n",
        "transformer_2 = compose.make_column_transformer(\n",
        "    (\n",
        "        preprocessing.StandardScaler(),\n",
        "        [\"age\", \"bmi\", \"bp\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]\n",
        "    ),\n",
        "    remainder=\"drop\",\n",
        "    verbose=True,\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "features_preprocessor = pipeline.make_union(\n",
        "    transformer_1,\n",
        "    transformer_2,\n",
        "    verbose=True,\n",
        "    n_jobs=-1\n",
        ").set_output(transform=\"pandas\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_preprocessor"
      ],
      "metadata": {
        "id": "wVua-L2qSz3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Preprocessing"
      ],
      "metadata": {
        "id": "mMC3l8bhR-CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_preprocessor = preprocessing.FunctionTransformer(\n",
        "    func=np.log,\n",
        "    inverse_func=np.exp\n",
        ")"
      ],
      "metadata": {
        "id": "tYtNbp53R3kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_preprocessor"
      ],
      "metadata": {
        "id": "pE2Ta5f1R30F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "2iKPEK7Wo7Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_engineering = preprocessing.PolynomialFeatures(\n",
        "    degree=2,\n",
        "    include_bias=False,\n",
        "    interaction_only=False\n",
        ").set_output(transform=\"pandas\")"
      ],
      "metadata": {
        "id": "xjuJ0RiAo-Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_engineering"
      ],
      "metadata": {
        "id": "4ROPfPL7S26F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "mrQRCXgMgSe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using ElasticNet"
      ],
      "metadata": {
        "id": "hbwT8oMLgVfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_regressor = compose.TransformedTargetRegressor(\n",
        "    linear_model.ElasticNet(\n",
        "        alpha=1e-3,\n",
        "        l1_ratio=0.5,\n",
        "        max_iter=4096,\n",
        "        fit_intercept=True,\n",
        "        random_state=prng,\n",
        "    ),\n",
        "    transformer=target_preprocessor\n",
        ")\n",
        "\n",
        "elastic_net_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    _regressor\n",
        ")"
      ],
      "metadata": {
        "id": "HEztScChgrzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = elastic_net_pipeline.fit(train_features, train_targets)"
      ],
      "metadata": {
        "id": "6nanFV14gYoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = elastic_net_pipeline.predict(train_features)\n",
        "train_rmse = metrics.mean_squared_error(\n",
        "    train_targets,\n",
        "    train_predictions,\n",
        "    squared=False\n",
        ")\n",
        "print(f\"Training rmse: {train_rmse}\")"
      ],
      "metadata": {
        "id": "VVCPbOT54NYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using SGDRegressor"
      ],
      "metadata": {
        "id": "h3JwOS2MhyJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.SGDRegressor?"
      ],
      "metadata": {
        "id": "d5mODlJHsWE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329CnQnEHUR-"
      },
      "outputs": [],
      "source": [
        "_regressor = compose.TransformedTargetRegressor(\n",
        "    linear_model.SGDRegressor(\n",
        "        penalty=\"elasticnet\",\n",
        "        alpha=1e-3,\n",
        "        l1_ratio=0.5,\n",
        "        fit_intercept=True,\n",
        "    ),\n",
        "    transformer=target_preprocessor\n",
        ")\n",
        "\n",
        "sgd_regressor_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    _regressor\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = sgd_regressor_pipeline.fit(train_features, train_targets)"
      ],
      "metadata": {
        "id": "xUNqtDeFhFj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = sgd_regressor_pipeline.predict(train_features)\n",
        "train_rmse = metrics.mean_squared_error(\n",
        "    train_targets,\n",
        "    train_predictions,\n",
        "    squared=False\n",
        ")\n",
        "print(f\"Training rmse: {train_rmse}\")"
      ],
      "metadata": {
        "id": "BpNMeohYl6jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model assessment"
      ],
      "metadata": {
        "id": "wWkdiCrXmAgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_neg_mses = model_selection.cross_val_score(\n",
        "    elastic_net_pipeline,\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ak_EtkyY-RcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_rmse = np.sqrt(np.mean(-cv_neg_mses))\n",
        "print(f\"ElasticNet CV rmse: {cv_rmse}\")"
      ],
      "metadata": {
        "id": "Ye7yb1_zQJny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_neg_mses = model_selection.cross_val_score(\n",
        "    sgd_regressor_pipeline,\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "JZdC_L7_e5_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_rmse = np.sqrt(np.mean(-cv_neg_mses))\n",
        "print(f\"SGDRegressor CV rmse: {cv_rmse}\")"
      ],
      "metadata": {
        "id": "crZdfvzNe7aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise:\n",
        "\n",
        "Is our current model under-fitting or over-fitting? How can you tell? What can you do to fix the problem?"
      ],
      "metadata": {
        "id": "MCcY9USoO3Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGQ7BzFEO99D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning model performance"
      ],
      "metadata": {
        "id": "jm9_q3GOhKLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using ElasticNetCV\n",
        "\n",
        "[ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html) is an example of a [cross-validation estimator](https://scikit-learn.org/stable/glossary.html#term-cross-validation-estimator). Cross-validation estimators are named `EstimatorCV` and tend to be roughly equivalent to `GridSearchCV(Estimator(), ...)`. The advantage of using a cross-validation estimator over the canonical estimator class along with grid search is that they can take advantage of warm-starting by reusing precomputed results in the previous steps of the cross-validation process.\n",
        "\n",
        "When calling `fit`, once the best parameters `l1_ratio` and `alpha` are found through cross-validation, the model is `fit` again using the entire training set."
      ],
      "metadata": {
        "id": "d4SrVjUr4guN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.ElasticNetCV?"
      ],
      "metadata": {
        "id": "H3b84RkZzU4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_cv = compose.TransformedTargetRegressor(\n",
        "    linear_model.ElasticNetCV(\n",
        "        cv=5,\n",
        "        eps=1e-3,\n",
        "        fit_intercept=True,\n",
        "        l1_ratio=np.logspace(-1, 0, 10),\n",
        "        max_iter=8192,\n",
        "        alphas=np.logspace(-4, 0, 10),\n",
        "        n_jobs=-1,\n",
        "        random_state=prng,\n",
        "        selection=\"random\",\n",
        "        verbose=0,\n",
        "    ),\n",
        "    transformer=target_preprocessor\n",
        ")\n",
        "\n",
        "tuned_elastic_net_pipeline = pipeline.make_pipeline(\n",
        "    features_preprocessor,\n",
        "    feature_engineering,\n",
        "    regressor_cv,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "TzIe5AuizIzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_elastic_net_pipeline"
      ],
      "metadata": {
        "id": "b4Kph3MC1M6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = tuned_elastic_net_pipeline.fit(train_features, train_targets)"
      ],
      "metadata": {
        "id": "y-q7DMDs06Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    tuned_elastic_net_pipeline.named_steps[\"transformedtargetregressor\"]\n",
        "                              .regressor_\n",
        "                              .alpha_\n",
        ")"
      ],
      "metadata": {
        "id": "qShxaci4WJ4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    tuned_elastic_net_pipeline.named_steps[\"transformedtargetregressor\"]\n",
        "                              .regressor_\n",
        "                              .l1_ratio_\n",
        ")"
      ],
      "metadata": {
        "id": "JflnVK1IWto-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using GridSearchCV and SGDRegressor"
      ],
      "metadata": {
        "id": "ntdY-4DLh-gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_sgd_regressor_pipeline = model_selection.GridSearchCV(\n",
        "    sgd_regressor_pipeline,\n",
        "    cv=5,\n",
        "    param_grid={\n",
        "        \"transformedtargetregressor__regressor__alpha\": np.logspace(-4, 0, 10),\n",
        "        \"transformedtargetregressor__regressor__l1_ratio\": np.logspace(-1, 0, 10)\n",
        "    },\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "mt0r-1O2oDUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_sgd_regressor_pipeline"
      ],
      "metadata": {
        "id": "3Asnemv_phFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = tuned_sgd_regressor_pipeline.fit(train_features, train_targets)"
      ],
      "metadata": {
        "id": "bfw469ahoDWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_sgd_regressor_pipeline.best_params_"
      ],
      "metadata": {
        "id": "bGSfl1Qyi8Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessing performance of the tuned model"
      ],
      "metadata": {
        "id": "xjm2nTimiXfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = tuned_elastic_net_pipeline.predict(train_features)\n",
        "train_rmse = metrics.mean_squared_error(\n",
        "    train_targets,\n",
        "    train_predictions,\n",
        "    squared=False\n",
        ")\n",
        "print(f\"ElasticNetCV training rmse: {train_rmse}\")"
      ],
      "metadata": {
        "id": "Mr5pHQxqijS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = tuned_elastic_net_pipeline.predict(test_features)\n",
        "test_rmse = metrics.mean_squared_error(\n",
        "    test_targets,\n",
        "    test_predictions,\n",
        "    squared=False\n",
        ")\n",
        "print(f\"ElasticNetCV testing rmse: {test_rmse}\")"
      ],
      "metadata": {
        "id": "_XhEX7fuu7Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = tuned_sgd_regressor_pipeline.predict(train_features)\n",
        "train_rmse = metrics.mean_squared_error(\n",
        "    train_targets,\n",
        "    train_predictions,\n",
        "    squared=False\n",
        ")\n",
        "print(f\"GridSearchCV + SGDRegressor training rmse: {train_rmse}\")"
      ],
      "metadata": {
        "id": "ChmXVMtcisEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = tuned_sgd_regressor_pipeline.predict(test_features)\n",
        "test_rmse = metrics.mean_squared_error(\n",
        "    test_targets,\n",
        "    test_predictions,\n",
        "    squared=False\n",
        ")\n",
        "print(f\"GridSearchCV + SGDRegressor Testing rmse: {test_rmse}\")"
      ],
      "metadata": {
        "id": "QYWJwp9qia0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Which of the two models should you prefer? Why?"
      ],
      "metadata": {
        "id": "A4Ooo0SZizSf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iftknph2i_0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}