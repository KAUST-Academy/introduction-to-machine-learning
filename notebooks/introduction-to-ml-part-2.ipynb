{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea2c52-3ead-4484-8a13-59ff459b0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import time\n",
    "\n",
    "import deepchem\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import compose, ensemble, metrics, model_selection\n",
    "from sklearn import pipeline, preprocessing, svm, tree, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b241c6-de2e-4c9a-ac4f-6c5a010e2929",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MoleculeNet\n",
    "\n",
    "One of the most powerful features of DeepChem is that it comes \"batteries included\" with datasets to use. The DeepChem developer community maintains the MoleculeNet [1] suite of datasets which maintains a large collection of different scientific datasets for use in machine learning applications. The original MoleculeNet suite had 17 datasets mostly focused on molecular properties. Over the last several years, MoleculeNet has evolved into a broader collection of scientific datasets to facilitate the broad use and development of scientific machine learning tools.\n",
    "\n",
    "These datasets are integrated with the rest of the DeepChem suite so you can conveniently access these these through functions in the dc.molnet submodule. You've already seen a few examples of these loaders already as you've worked through the tutorial series. The full documentation for the MoleculeNet suite is available in our docs [2].\n",
    "\n",
    "[1] Wu, Zhenqin, et al. \"MoleculeNet: a benchmark for molecular machine learning.\" Chemical science 9.2 (2018): 513-530.\n",
    "\n",
    "[2] https://deepchem.readthedocs.io/en/latest/moleculenet.html\n",
    "\n",
    "\n",
    "## Delaney (ESOL) Dataset\n",
    "\n",
    "The [Delaney (ESOL) dataset](https://pubs.acs.org/doi/pdf/10.1021/ci034243x) is a regression dataset containing structures and water solubility data for 1128 compounds. The dataset is widely used to validate machine learning models on estimating solubility directly from molecular structures (as encoded in [SMILES strings](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system).\n",
    "\n",
    "The raw data csv file contains columns below:\n",
    "\n",
    "* Compound ID - Name of the compound\n",
    "* ESOL predicted log solubility in mols per litre\n",
    "* Minimum Degree\n",
    "* Molecular Weight\n",
    "* Number of H-Bond Donors\n",
    "* Number of Rings\n",
    "* Number of Rotatable Bonds\n",
    "* Polar Surface Area\n",
    "* measured log solubility in mols per litre - Log-scale water solubility of the compound, used as label\n",
    "* smiles - SMILES representation of the molecular structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d2238-7283-441a-b6d8-4ba3c4c682f0",
   "metadata": {},
   "source": [
    "### Download and extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09916110-f2d8-448c-86ee-4be9ae5be169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"../data/moleculenet/delaney\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_, (dataset,), _ = (deepchem.molnet\n",
    "                            .load_delaney(\n",
    "                                data_dir=DATA_DIR,\n",
    "                                reload=False,\n",
    "                                save_dir=DATA_DIR,\n",
    "                                splitter=None,\n",
    "                                transformers=[],\n",
    "                            )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc24c9-260e-4840-8872-723f0adc6f41",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "We can use the following code to quickly look at the first few lines of the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78bdf7-1d86-4ff5-83e1-6f80d3e9a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "head ../data/moleculenet/delaney/delaney-processed.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0bff8c-714a-4451-bd02-057a6fc75e71",
   "metadata": {},
   "source": [
    "We will load the data using the [Pandas](https://pandas.pydata.org/) library. Highly recommend the most recent edition of [*Python for Data Analysis*](https://learning.oreilly.com/library/view/python-for-data/9781491957653/) by Pandas creator Wes Mckinney for anyone interested in learning how to use Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fded7d-02a7-48c3-99e4-d19d001c8ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_usecols = [\n",
    "    \"ESOL predicted log solubility in mols per litre\",\n",
    "    \"Minimum Degree\",\n",
    "    \"Molecular Weight\",\n",
    "    \"Number of H-Bond Donors\",\n",
    "    \"Number of Rings\",\n",
    "    \"Number of Rotatable Bonds\",\n",
    "    \"Polar Surface Area\", \n",
    "    \"measured log solubility in mols per litre\",\n",
    "    \"smiles\",\n",
    "]\n",
    "\n",
    "data = pd.read_csv(\n",
    "    DATA_DIR / \"delaney-processed.csv\",\n",
    "    usecols=_usecols,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d7ed7-50ae-46fb-b7c9-cb3cbd5a6f1b",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0a7b5-2310-4261-82a8-6994d1bd6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f1446-4059-4365-8971-63265f900153",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data.hist(bins=50, figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed0717-7763-4b87-b893-a2f761e2af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.corr()\n",
    "     .loc[:, \"measured log solubility in mols per litre\"]\n",
    "     .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eab530-5edf-4f1e-888b-4789544bc51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (pd.plotting\n",
    "       .scatter_matrix(data, figsize=(12, 8)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4ac98-a018-4012-b7df-7472f11f8601",
   "metadata": {},
   "outputs": [],
   "source": [
    "_esol_predictions_label = \"ESOL predicted log solubility in mols per litre\"\n",
    "_target_label = \"measured log solubility in mols per litre\"\n",
    "features = data.drop([_esol_predictions_label, _target_label], axis=1)\n",
    "esol_predictions = data.loc[:, _esol_predictions_label]\n",
    "target = data.loc[:, _target_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53a9c4-550d-4577-bf0f-bace74843784",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a672145-6e4a-4a8f-9354-773c665e6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4983c89-dcbf-4403-8d76-7940d95c9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305221d-0e83-415f-b85c-018ef6a79cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedd25d-8938-42a8-94bd-0096988a4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5d4e9-8c96-4da9-b9b7-33a0edbe018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76e54f-947c-4123-89c6-e59eedc3621b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Look at the Big Picture\n",
    "\n",
    "Our goal over this three day hands-on workshop is to build a machine learning modeling pipeline that is capable of accurately predicting water solubility of chemical compounds. Today and tomorrow we will mostly focus on classical machine learning algorithms implemented in Scikit-Learn; on the final day we will revist the same problem using deep learning algorithms implemented in PyTorch. By the time you have finished this workshop you should understand how to build a machine learning application and be ready to apply what you have learned to a new dataset.\n",
    "\n",
    "Prior to the break we will mostly focus on getting the data and exploring the data to gain new insights. Believe it or not these initial steps are what data scientists and machine learning engineers spend the majority of their time doing! Following the break we will prepare our data for machine learning, see how to fit a variety of machine learning models to our dataset and shortlist a few candidate models for further analysis. We will then use hyper-parameter tuning to improve the performance of our shortlisted models to arrive at an overall best model.\n",
    "\n",
    "## Framing the problem\n",
    "\n",
    "### What is the business/research objective?\n",
    "\n",
    "Typically building the model is not the overall objective but rather the model itself is one part of a larger process used to answer a business/research question. Knowing the overall objective is important because it will determine your choice of machine learning algorithms to train, your measure(s) of model performance, and how much time you will spend tweaking the hyper-parameters of your model.\n",
    "\n",
    "In our example today, the overall business/research objective is to build a model capable of estimating the solubility of chemical compounds. Our solubility model is just one of potentially many other models whose predictions are taken as inputs into another machine learning models that will be used to aid in drug discovery.\n",
    "\n",
    "### What is the current solution?\n",
    "\n",
    "Always a good idea to know what the current solution to the problem you are trying to solve. Current solution gives a benchmark for performance. Note that the current \"best\" solution could be very simple or could be very sophisticated. Understanding the current solution helps you think of a good place to start.\n",
    "\n",
    "With all this information, you are now ready to start designing your system. First, you need to frame the problem by answering the following questions.\n",
    "\n",
    "* Is our problem supervised, unsupervised, or reinforcement learning?\n",
    "* Is our problem a classification task, a regression task, or something else? If our problem is a classification task are we trying to classify samples into 2 categories (binary classification) or more than 2 (multi-class classification) categories? If our problem is a regression task, are we trying to predict a single value (univariate regression) or multiple values (multivariate regression) for each sample?\n",
    "* Should you use batch learning or online learning techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52576a2-4c8e-4707-b021-2e424c4633ee",
   "metadata": {},
   "source": [
    "### Exercise: Selecting a metric\n",
    "\n",
    "Scikit-Learn has a number of different [possible metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) that you can choose from (or you can create your own custom metric if required). Can you find a few metrics that seems appropriate for our regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2212c9-f227-4b8f-ac41-6deb6f714976",
   "metadata": {},
   "source": [
    "# Creating a Test Dataset\n",
    "\n",
    "Before we look at the data any further, we need to create a test set, put it aside, and never look at it (until we are ready to test our trainined machine learning model!). Why? We don't want our machine learning model to memorize our dataset (this is called overfitting). Instead we want a model that will generalize well (i.e., make good predictions) for inputs that it didn't see during training. To do this we hold split our dataset into training and testing datasets. The training dataset will be used to train our machine learning model(s) and the testing dataset will be used to make a final evaluation of our machine learning model(s).\n",
    "\n",
    "## If you might refresh data in the future...\n",
    "\n",
    "...then you want to use some particular hashing function to compute the hash of a unique identifier for each observation of data and include the observation in the test set if resulting hash value is less than some fixed percentage of the maximum possible hash value for your algorithm. This way even if you fetch more data, your test set will never include data that was previously included in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba37993-2014-4267-9589-fe88d0b21090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "\n",
    "def in_testing_data(identifier, test_size):\n",
    "    _hash = zlib.crc32(bytes(identifier))\n",
    "    return _hash & 0xffffffff < test_size * 2**32\n",
    "\n",
    "\n",
    "def split_train_test_by_id(data, test_size, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda identifier: in_testing_data(identifier, test_size))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c73954-f3a5-464b-b179-17f7fbe142fb",
   "metadata": {},
   "source": [
    "## If this is all the data you will ever have...\n",
    "\n",
    "...then you can just set a seed for the random number generator and then randomly split the data. Scikit-Learn has a [`model_selection`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) module that contains tools for splitting datasets into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791e74d-cddd-4383-8a6c-5b80df4a5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35bf11-0fa5-4879-bbda-e976244ec929",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "SEED_GENERATOR = np.random.RandomState(SEED)\n",
    "\n",
    "\n",
    "def generate_seed():\n",
    "    return SEED_GENERATOR.randint(np.iinfo(\"uint16\").max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff5a36-07c7-404f-916b-260c789aff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing data\n",
    "_seed = generate_seed()\n",
    "_random_state = np.random.RandomState(_seed)\n",
    "train_features, test_features, train_target, test_target, train_esol_predictions, test_esol_predictions = model_selection.train_test_split(\n",
    "    features,\n",
    "    target,\n",
    "    esol_predictions,\n",
    "    test_size=1e-1,\n",
    "    random_state=_random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed741c-996c-4df3-8680-49f14cc0dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722a295-4c88-4d24-b5cc-b84282f3de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8337f0-65ea-4f5c-90a8-f5609e6cb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esol_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090af9ae-e36c-4c5d-ac2d-25e1ea1c34df",
   "metadata": {},
   "source": [
    "Again, if you want to you can write out the train and test sets to disk to avoid having to recreate them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede1948-a85a-450f-8c0b-8c18b56ed4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (train_features.join(train_target)\n",
    "                   .join(train_esol_predictions)\n",
    "                   .to_csv(DATA_DIR / \"train.csv\", index=False))\n",
    "\n",
    "_ = (test_features.join(test_target)\n",
    "                  .join(test_esol_predictions)\n",
    "                  .to_csv(DATA_DIR / \"test.csv\", index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280e020-f990-434c-98b9-361321134432",
   "metadata": {},
   "source": [
    "# Prepare the data for machine learning algorithms\n",
    "\n",
    "Best practice is to write functions to automate the process of preparing your data for machine learning. Why?\n",
    "\n",
    "* Allows you to reproduce these transformations easily on any dataset.\n",
    "* You will gradually build a library of transformation functions that you can reuse in future projects.\n",
    "* You can use these functions in a live system to transform the new data before feeding it to your algorithms.\n",
    "* This will make it possible for you to easily experiment with various transformations and see which combination of transformations works best.\n",
    "\n",
    "We are working with an benchmark dataset that has already been prepared for analysis (mostly!). You should be aware that academic benchmark datasets are not very representative of the type of datasets that you will encounter in most practical applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626fd519-ffb6-4ae9-be55-53d4a54e53c5",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Machine learning algorithms typically don’t perform well when the input numerical attributes have very different scales. One of the most common approaches is to rescale features so that they all have zero mean and unit standard deviation. This approach, which is also called standardization, is particularly useful when attributes/features have outliers and when downstream machine learning algorithms assume that attributes/features have a Gaussian or Normal distribution. This approach is implemented in Scikit-Learn by the [`preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.StandardScaler) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f4f98-aa73-46b0-82ce-ebf0d4a0ff81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing.StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fe28e-a285-4e87-979e-462be36d0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "_hyperparameters = {\n",
    "    \"copy\": True,\n",
    "    \"with_mean\": True,\n",
    "    \"with_std\": True,\n",
    "}\n",
    "preprocessor = preprocessing.StandardScaler(**_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca8616-d29f-4d47-888c-841f6b823b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_cardinal_labels = [\n",
    "    \"Molecular Weight\",\n",
    "    \"Polar Surface Area\",\n",
    "]\n",
    "_train_cardinal_features = train_features.loc[:, _cardinal_labels]\n",
    "preprocessed_train_cardinal_features = preprocessor.fit_transform(_train_cardinal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07170a9-6cb0-4474-8bab-15fec52acc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_cardinal_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bf42d-6a72-4b7d-b768-412d5edcb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_cardinal_features[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034122d4-e0e8-4db9-95b1-0c46b733209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_cardinal_features.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2306826-abb1-4575-bd53-14f0742131a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_cardinal_features.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd7f6c-0c01-46aa-b2c3-8dce85005f76",
   "metadata": {},
   "source": [
    "The `preprocessing.MinMaxScaler` and the `preprocessing.StandardScaler` classes are the first Scikit-Learn `Transformer` classes that we have encountered. As such now is a good to to discuss the Scikit-Learn application programming interface (API). The [Scikit-Learn API](https://scikit-learn.org/stable/modules/classes.html) is one of the best designed API's around and has heavily influenced API design choices of other libraries in the Python Data Science and Machine Learning ecosystem, in particular [Dask](https://dask.org/) and [NVIDIA RAPIDS](https://rapids.ai/). Familiarly with the Scikit-Learn API will make it easier for you to get started with these libraries.\n",
    "\n",
    "The Scikit-Learn API is built around the following key concepts.\n",
    "\n",
    "* Estimators: Any object that can estimate some parameters based on a dataset is called an estimator (e.g., an `preprocessing.MinMaxScaler` is an estimator). The estimation itself is performed by the `fit` method, and it takes only a dataset as a parameter (or two for supervised learning algorithms; the second dataset contains the labels). Any other parameter needed to guide the estimation process is considered a hyperparameter (such as the `feature_range` parameter in `preprocessing.MinMaxScaler`), and it must be set as an instance variable (generally via a constructor parameter).\n",
    "\n",
    "* Transformers: Some estimators (such as an `preprocessing.MinMaxScaler`) can also transform a dataset; these are called transformers. Once again, the API is simple: the transformation is performed by the transform method with the dataset to transform as a parameter. It returns the transformed dataset. This transformation generally relies on the learned parameters. All transformers also have a convenience method called `fit_transform` that is equivalent to calling `fit` and then `transform` (but sometimes `fit_transform` is optimized and runs much faster).\n",
    "\n",
    "* Predictors: Finally, some estimators, given a dataset, are capable of making predictions; they are called predictors. A predictor has a `predict` method that takes a dataset of new instances and returns a dataset of corresponding predictions. It also has a score method that measures the quality of the predictions, given a test set (and the corresponding labels, in the case of supervised learning algorithms).\n",
    "\n",
    "All of an estimator’s hyperparameters are accessible directly via public instance variables (e.g., `preprocessor.feature_range`), and all the estimator’s learned parameters are accessible via public instance variables with an underscore suffix (e.g., `preprocessor.scale_`). Finally, Scikit-Learn provides reasonable default values for most parameters which makes it easy to quickly create a baseline working system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd0ab6-3d65-466c-b2d6-8926601d4f3d",
   "metadata": {},
   "source": [
    "### Exercise: MinMaxScaler vs StandardScaler\n",
    "\n",
    "An alternative to standard scaling is to rescale features so that they all reside within the same range (typically between 0 and 1).\n",
    "\n",
    "Create an instance of the [`preprocessing.MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) class and use it to rescale the training dataset. Compare the two different rescaled versions of the dataset. Which of the two methods do you prefer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ce5ba-4568-4f39-a620-93b7fe402396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04a639-ba99-47b5-936a-7c6a555c6f08",
   "metadata": {},
   "source": [
    "As with all the transformations, it is important to fit the scalers to the training data only, not to the full dataset (including the test set). Only then can you use them to transform the training set and the test set (and new data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c62f5c-21cd-4138-8776-baca812ba3d9",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is one of the most important parts of any machine learning project. There are two main tasks in feature engineering.\n",
    "\n",
    "* Feature selection: selecting the best subset of features for training. \n",
    "* Feature extraction: combining existing features to produce new features for training.\n",
    "* Feature creation: finding additional data sources to use as features.\n",
    "\n",
    "Feature engineering is often the most labor intensive part of building a machine learning pipeline and often requires extensive expertise/domain knowledge relevant to the problem at hand. Recently packages such as [featuretools](https://www.featuretools.com/) have been developed to (partially) automate the process of feature engineering.\n",
    "\n",
    "The success of deep learning in various domains is in significant part due to the fact that deep learning models are able to automatically engineer features that are most useful for solving certain machine learning tasks. In effect deep learning replaces the expensive to acquire expertise/domain knowledge required to hand-engineer predictive features. \n",
    "\n",
    "A recent example that demonstrates that power of automated feature engineering is [Space2vec](https://medium.com/dessa-news/space-2-vec-fd900f5566), a deep learning based supernovae classifier developed by machine learning engineers with no expertise in Astronomy that was able to outperform the machine learning solution developed by NERSC scientists. The machine learning pipeline developed by NERSC scientists, called [AUTOSCAN](https://portal.nersc.gov/project/dessn/autoscan/), was a significant improvement over the previous solution which relied on manual classification of supernovae by astronomers. However, in order to achieve such high accuracy, the NERSC solution relied on a dataset of hand-engineered features developed by astronomers with over a century of combined training and expertise in the domain. The deep learning algorithm used by space2vec could be applied directly to the raw image data and did not rely on any hand-engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077a1e5-6756-4ca5-b054-7cf8b399b30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deepchem.molnet.load_delaney?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f5355-d451-4aab-b4de-fc8ca4b6713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b258fe6-475d-46f1-8349-9be26ae9f70e",
   "metadata": {},
   "source": [
    "## Transformation pipelines\n",
    "\n",
    "As you can see creating preprocessing pipelines involves quite a lot of steps and each of the steps needs to be executed in the correct order. Fortunately Scikit-Learn allows you to combine estimators together to create [pipelines](https://scikit-learn.org/stable/modules/compose.html#combining-estimators). We can encapsulate all of the preprocessing logic into instances of the [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) class.\n",
    "\n",
    "The `Pipeline` constructor takes a list of name/estimator pairs defining a sequence of steps. All but the last estimator must be transformers (i.e., they must have a `fit_transform` method). The names can be anything you like (as long as they are unique). Later we will see how to access the parameters of pipelines using these names when we discuss hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c387af-af54-4c57-a9a5-548672737cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"copy\": True,\n",
    "    \"with_mean\": True,\n",
    "    \"with_std\": True,\n",
    "}\n",
    "\n",
    "# default Pipeline constructor\n",
    "cardinal_pipeline = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"standardscaler\", preprocessing.StandardScaler(**_hyperparameters)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"feature_range\": (0, 1),\n",
    "    \"copy\": True,\n",
    "    \"clip\": False,\n",
    "}\n",
    "ordinal_pipeline = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"minmaxscaler\", preprocessing.MinMaxScaler(**_hyperparameters)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a4738-3b10-4803-9d6b-9e72f0d6e674",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Custom transformers\n",
    "\n",
    "Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom transformations, cleanup operations, or combining specific attributes.\n",
    "\n",
    "For transformations that don’t require any training, you can just write a function that takes a NumPy array as input, and outputs the transformed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f069d-25dd-4b86-9bb7-db78ba85f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_featurized_smiles = (dataset.to_dataframe()\n",
    "                             .drop(['y', 'w', \"ids\"], axis=1))\n",
    "\n",
    "def featurizer(object_features):\n",
    "    ixs = object_features.index\n",
    "    return _featurized_smiles.loc[ixs, :]\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"func\": featurizer,\n",
    "}\n",
    "\n",
    "non_numeric_pipeline = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"functiontransformer\", preprocessing.FunctionTransformer(**_hyperparameters)),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1aa017-cc1d-4d5a-b6cb-1107d8c8c459",
   "metadata": {},
   "source": [
    "The code in the cell below creates the same pipelines as above but use the `pipeline.make_pipeline` function which automaticlly generates names for the different stages of the pipeline using the class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034f083-3b70-4113-a971-883ee1f5d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"copy\": True,\n",
    "    \"with_mean\": True,\n",
    "    \"with_std\": True,\n",
    "}\n",
    "\n",
    "# alternative constructor that is equivalent to the above!\n",
    "cardinal_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(**_hyperparameters),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"feature_range\": (0, 1),\n",
    "    \"copy\": True,\n",
    "    \"clip\": False,\n",
    "}\n",
    "\n",
    "ordinal_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler(**_hyperparameters),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_featurized_smiles = (dataset.to_dataframe()\n",
    "                             .drop(['y', 'w', \"ids\"], axis=1))\n",
    "\n",
    "def featurizer(object_features):\n",
    "    ixs = object_features.index\n",
    "    return _featurized_smiles.loc[ixs, :]\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"func\": featurizer,\n",
    "}\n",
    "non_numeric_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.FunctionTransformer(**_hyperparameters),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47685d3-e8bb-4a4c-b7fc-30bff4519977",
   "metadata": {},
   "source": [
    "So far, we have handled the non-numeric columns and the numeric columns separately. It would be more convenient to have a single transformer capable of handling all columns, applying the appropriate transformations to each column. For this, you can use a [`compose.ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c56b1-52b9-41de-b0b3-42c716ca709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = compose.make_column_transformer(\n",
    "    (cardinal_pipeline, compose.make_column_selector(dtype_include=np.float64)),\n",
    "    (ordinal_pipeline, compose.make_column_selector(dtype_include=np.int64)),\n",
    "    (non_numeric_pipeline, compose.make_column_selector(dtype_include=object)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54355bfd-265c-4604-aece-3d2afb427c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_features = preprocessing_pipeline.fit_transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf29f60-309d-4107-9ef0-f1d42403d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c91d3d-f2ea-48a1-b7fa-204bc9f1ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_features[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b292be-f7b9-4958-a6d0-c957ebcc50a5",
   "metadata": {},
   "source": [
    "# Select and train a model\n",
    "\n",
    "At last! You framed the problem, you got the data and explored it, you sampled a training set and a test set, and you wrote transformation pipelines to clean up and prepare your data for machine learning algorithms automatically. You are now ready to select and train a Machine Learning model. You might have been wondering if we were every going to make it to this point! Fact is, most of your time developing machine learning solutions to real-world problems will not be spent training machine learning models: most of your time will be spent preparing the data for machine learning algorithms and most of the computer time will be spent training the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627d70a-418f-49ed-8449-5ba412a77d2c",
   "metadata": {},
   "source": [
    "## Training and evaluating on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c9bd5-d21a-43e1-96b2-33bedcc54e7e",
   "metadata": {},
   "source": [
    "### Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c72276-0e16-42a1-ac5b-779620bbdae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm.LinearSVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c868d-0835-427d-a668-63809b70e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"epsilon\": 0.0,\n",
    "    \"tol\": 0.0001,\n",
    "    \"C\": 1.0,\n",
    "    \"loss\": 'epsilon_insensitive',\n",
    "    \"fit_intercept\": True,\n",
    "    \"intercept_scaling\": 1.0,\n",
    "    \"dual\": True,\n",
    "    \"verbose\": 0,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"max_iter\": 5000,\n",
    "}\n",
    "estimator = svm.LinearSVR(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc88278-3197-41f0-9600-527206c34c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = estimator.predict(preprocessed_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324613b-9ddc-4c2b-b0e7-b0ff34cc3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(\n",
    "    train_target,\n",
    "    predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee5c9e-dfe7-481f-995c-9c9720a4c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_FOLDS = 5\n",
    "\n",
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe905e6a-c60a-4b1c-bee5-eeb8bcc3c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada04802-5ae9-4285-bdd5-d8b6ae40057e",
   "metadata": {},
   "source": [
    "Looks like our linear SVM is overfitting the data significantly: we need to regularize!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110beab-d79a-49dc-b314-ebbb898efb68",
   "metadata": {},
   "source": [
    "### Exercise: Regularizing `svm.LinearSVR`\n",
    "\n",
    "What hyperparameters of `svm.LinearSVR` should be tuned in order to regularize the model and reduce overfitting? See if you can find a decent set of hyperparameters that might serve as a good starting point for automated hyperparameter optimization.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f13789-4069-473d-a3f5-314453430d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm.LinearSVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df85d9-c099-404b-8fcb-d9650a7d9d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"epsilon\": 0.0,\n",
    "    \"tol\": 0.0001,\n",
    "    \"C\": 1.0,\n",
    "    \"loss\": 'epsilon_insensitive',\n",
    "    \"fit_intercept\": True,\n",
    "    \"intercept_scaling\": 1.0,\n",
    "    \"dual\": True,\n",
    "    \"verbose\": 0,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"max_iter\": 5000,\n",
    "}\n",
    "estimator = svm.LinearSVR(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b11185-92e7-4cb6-b938-d12bdc4f5eae",
   "metadata": {},
   "source": [
    "### Non-linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb57fa-c8b1-4559-a8ef-94b112672e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svm.SVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704c70e7-5bb5-4349-9431-ff32408743e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"degree\": 3,\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.0,\n",
    "    \"tol\": 0.001,\n",
    "    \"C\": 1.0,\n",
    "    \"epsilon\": 0.1,\n",
    "    \"shrinking\": True,\n",
    "    \"cache_size\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"max_iter\": -1,\n",
    "}\n",
    "estimator = svm.SVR(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "predictions = estimator.predict(preprocessed_train_features)\n",
    "mse = metrics.mean_squared_error(\n",
    "    train_target,\n",
    "    predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8a6f8-fcc8-42ac-b69e-b481c95b166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0ee00-6dec-495b-81db-addff2bd1036",
   "metadata": {},
   "source": [
    "### Exercise: Regularizing `svm.SVR`\n",
    "\n",
    "What hyperparameters of `svm.SVR` should be tuned in order to regularize the model and reduce overfitting? See if you can find a decent set of hyperparameters that might serve as a good starting point for automated hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed980cff-ac48-4d2a-bac8-6de354860e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.SVR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba2523-29a6-4c69-9bd0-e031af1b5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_hyperparameters = {\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"degree\": 3,\n",
    "    \"gamma\": \"scale\",\n",
    "    \"coef0\": 0.0,\n",
    "    \"tol\": 0.001,\n",
    "    \"C\": 1.0,\n",
    "    \"epsilon\": 0.1,\n",
    "    \"shrinking\": True,\n",
    "    \"cache_size\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"max_iter\": -1,\n",
    "}\n",
    "estimator = svm.SVR(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadeb7f8-ee55-4fe6-91f1-4beaf306affc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e48d0-9472-4772-841d-7f82b2fb35cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree.DecisionTreeRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e621a3-e58a-439f-b08c-7307dac90f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"splitter\": \"best\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": None,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "}\n",
    "estimator = tree.DecisionTreeRegressor(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "predictions = estimator.predict(preprocessed_train_features)\n",
    "mse = metrics.mean_squared_error(\n",
    "    train_target,\n",
    "    predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd92db5-7e2e-48c7-b3cb-476caccf3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a8465-e49f-45e2-a44c-f6b2002db06f",
   "metadata": {},
   "source": [
    "### Exercise: Regularizing `tree.DecisionTreeRegressor`\n",
    "\n",
    "What hyperparameters of `tree.DecisionTreeRegressor` should be tuned in order to regularize the model and reduce overfitting? See if you can find a decent set of hyperparameters that might serve as a good starting point for automated hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b0d88-7a3a-4826-b586-2988fd74152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"splitter\": \"best\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": None,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "}\n",
    "estimator = tree.DecisionTreeRegressor(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78517f47-a75d-4584-801b-51f5ad3d517d",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c577d-efe5-4442-94b0-5957e6fea281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble.RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb3f6d-e535-4e3d-b81d-b4f3ee7d2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": 1.0,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"max_samples\": None,\n",
    "}\n",
    "estimator = ensemble.RandomForestRegressor(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "predictions = estimator.predict(preprocessed_train_features)\n",
    "mse = metrics.mean_squared_error(\n",
    "    train_target,\n",
    "    predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb81c20-0fca-4d51-a2de-f408d0f2475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf715f8-e2c2-4c5a-a47b-e80d97f26853",
   "metadata": {},
   "source": [
    "### Exercise: Regularizing `ensemble.RandomForestRegressor`\n",
    "\n",
    "What hyperparameters of `ensemble.RandomForestRegressor` should be tuned in order to regularize the model and reduce overfitting? See if you can find a decent set of hyperparameters that might serve as a good starting point for automated hyperparameter optimization. How can you use bagging to estimate the generalization error (and avoid the compute costs of cross-validation)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c83ae8-16a4-44d7-abba-4cae4c30a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": 1.0,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"n_jobs\": -1,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"max_samples\": None,\n",
    "}\n",
    "estimator = ensemble.RandomForestRegressor(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc8c02-6606-4aba-aa70-66e71ee2c681",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffaf41-dc7f-4ed9-b4d6-a2a590cf2806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble.HistGradientBoostingRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94093424-337d-4f60-9240-56a2ed8f7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"loss\": \"squared_error\",\n",
    "    \"quantile\": None,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_iter\": 100,\n",
    "    \"max_leaf_nodes\": 31,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_leaf\": 20,\n",
    "    \"l2_regularization\": 0.0,\n",
    "    \"max_bins\": 255,\n",
    "    \"categorical_features\": None,\n",
    "    \"monotonic_cst\": None,\n",
    "    \"warm_start\": False,\n",
    "    \"early_stopping\": 'auto',\n",
    "    \"scoring\": \"loss\",\n",
    "    \"validation_fraction\": 0.1,\n",
    "    \"n_iter_no_change\": 10,\n",
    "    \"tol\": 1e-07,\n",
    "    \"verbose\": 0,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "}\n",
    "estimator = ensemble.HistGradientBoostingRegressor(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)\n",
    "\n",
    "predictions = estimator.predict(preprocessed_train_features)\n",
    "mse = metrics.mean_squared_error(\n",
    "    train_target,\n",
    "    predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c320489-9678-4a21-a04a-0ca4320ba366",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_scores = model_selection.cross_val_score(\n",
    "    estimator,\n",
    "    X=preprocessed_train_features,\n",
    "    y=train_target,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "valid_error = -estimator_scores.mean()\n",
    "print(f\"Estimated generalization error: {valid_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12888fdd-683c-4064-aca4-23f54de3f6a2",
   "metadata": {},
   "source": [
    "### Exercise: Regularizing `ensemble.HistGradientBoostingRegressor`\n",
    "\n",
    "What hyperparameters of `ensemble.HistGradientBoostingRegressor` should be tuned in order to regularize the model and reduce overfitting? See if you can find a decent set of hyperparameters that might serve as a good starting point for automated hyperparameter optimization. How can you use bagging to estimate the generalization error (and avoid the compute costs of cross-validation)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af4eb2-f326-4c5d-970e-758e189411a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "_hyperparameters = {\n",
    "    \"loss\": \"squared_error\",\n",
    "    \"quantile\": None,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_iter\": 100,\n",
    "    \"max_leaf_nodes\": 31,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_leaf\": 20,\n",
    "    \"l2_regularization\": 0.0,\n",
    "    \"max_bins\": 255,\n",
    "    \"categorical_features\": None,\n",
    "    \"monotonic_cst\": None,\n",
    "    \"warm_start\": False,\n",
    "    \"early_stopping\": 'auto',\n",
    "    \"scoring\": \"loss\",\n",
    "    \"validation_fraction\": 0.1,\n",
    "    \"n_iter_no_change\": 10,\n",
    "    \"tol\": 1e-07,\n",
    "    \"verbose\": 0,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "}\n",
    "estimator = ensemble.HistGradientBoostingRegressor(**_hyperparameters)\n",
    "_ = estimator.fit(preprocessed_train_features, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4480006-5cd1-467d-bc1d-be8a52d7abd6",
   "metadata": {},
   "source": [
    "# Fine-tune your models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09227c31-3011-4e3e-b024-7e4cc7468093",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "Simplest approach is to use Scikit-Learn’s [`model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). All you need to do is tell it which hyperparameters you want it to experiment with and what values to try out. The `model_selection.GridSearchCV` class will then use cross-validation to evaluate all the possible combinations of hyperparameter values and return the best scoring set of hyperparameters according to your specified metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29dd37-ec17-40a4-abeb-b9a666c09766",
   "metadata": {},
   "source": [
    "### Exercise: Tune your own model!\n",
    "\n",
    "Select one of the model that you manually tuned above and then tune it further using `model_selection.GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c7ffa-c6b6-4003-a1a0-57abc5d27080",
   "metadata": {},
   "outputs": [],
   "source": [
    "_seed = generate_seed()\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"copy\": True,\n",
    "    \"with_mean\": True,\n",
    "    \"with_std\": True,\n",
    "}\n",
    "\n",
    "# alternative constructor that is equivalent to the above!\n",
    "cardinal_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(**_hyperparameters),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"feature_range\": (0, 1),\n",
    "    \"copy\": True,\n",
    "    \"clip\": False,\n",
    "}\n",
    "\n",
    "ordinal_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler(**_hyperparameters),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_featurized_smiles = (dataset.to_dataframe()\n",
    "                             .drop(['y', 'w', \"ids\"], axis=1))\n",
    "def featurizer(object_features):\n",
    "    ixs = object_features.index\n",
    "    return _featurized_smiles.loc[ixs, :]\n",
    "\n",
    "_hyperparameters = {\n",
    "    \"func\": featurizer,\n",
    "}\n",
    "non_numeric_pipeline = pipeline.make_pipeline(\n",
    "    preprocessing.FunctionTransformer(**_hyperparameters),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_preprocessing_pipeline = compose.make_column_transformer(\n",
    "    (cardinal_pipeline, compose.make_column_selector(dtype_include=np.float64)),\n",
    "    (ordinal_pipeline, compose.make_column_selector(dtype_include=np.int64)),\n",
    "    (non_numeric_pipeline, compose.make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "_seed = generate_seed()\n",
    "_random_state = np.random.RandomState(_seed)\n",
    "_hyperparameters = {\n",
    "    \"fit_intercept\": True,\n",
    "    \"loss\": \"squared_error\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"random_state\": np.random.RandomState(_seed),\n",
    "}\n",
    "_pipeline = pipeline.make_pipeline(\n",
    "    _preprocessing_pipeline,\n",
    "    # insert your model here!,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "_parameter_grid = [\n",
    "    # insert parameter grid here!\n",
    "]\n",
    "\n",
    "estimator = model_selection.GridSearchCV(\n",
    "    _pipeline,\n",
    "    _parameter_grid,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    pre_dispatch=2, # important to set this properly to avoid OOM errors\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d47f2-a368-44cb-9c28-50667776077d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = estimator.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39895ae-2739-44fc-9b9e-a8456f5c667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c7059-dec2-4f07-b2fb-058e860025a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56606c-1216-41e8-9f49-4c8afaa86cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb75865-e210-406e-9902-705fa06b52c1",
   "metadata": {},
   "source": [
    "You should save every model you experiment with so that you can come back easily to any model you want. Make sure you save both the hyperparameters and the trained parameters as well as the cross-validation scores and perhaps the actual predictions as well. This will allow you to more easily compare scores across model types and compare the types of errors they make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b63ee-6d09-4de9-8a7b-26bf301cde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = pathlib.Path(\"../results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "_ = joblib.dump(estimator, RESULTS_DIR / f\"grid-search-cv-regressor-{timestamp}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe59c5d-9048-4385-9766-874f332e44db",
   "metadata": {},
   "source": [
    "For reference here is how you would reload the trained model from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846db76e-d988-48ab-b43a-8329f3f889f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_estimator = joblib.load(RESULTS_DIR / f\"grid-search-cv-regressor-{timestamp}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db94fb6-e955-4edc-95d0-edfa55d6bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d6d00-4881-4def-bf0a-88219991d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7255e-4f60-469c-b541-f6935d9cb6e1",
   "metadata": {},
   "source": [
    "# Evaluate your models on the test dataset\n",
    "\n",
    "After tweaking your models for a while, you eventually have a system that performs sufficiently well. Now is the time to evaluate the final model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73ca70-1d2b-4053-b500-5d0be0c19f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = estimator.predict(test_features)\n",
    "\n",
    "# report the error on the test set\n",
    "mse = metrics.mean_squared_error(\n",
    "    test_target,\n",
    "    predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8f0a1-eb35-445c-8fa3-0e2ffc1e8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the error on the training set\n",
    "mse = metrics.mean_squared_error(\n",
    "    test_target,\n",
    "    test_esol_predictions,\n",
    ")\n",
    "print(f\"Root mean squared error: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55224491-47cc-443d-8592-65fd362e4128",
   "metadata": {},
   "source": [
    "If you did a lot of hyperparameter tuning, the performance will usually be slightly worse than what you measured using cross-validation (because your system ends up fine-tuned to perform well on the validation data and will likely not perform as well on unknown datasets). It is not the case in this example, but when this happens you must resist the temptation to tweak the hyperparameters to make the numbers look good on the test set; the improvements would be unlikely to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cedef-b497-4eda-9bbd-ab04263e2087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
